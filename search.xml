<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[CNN Flower Recognition]]></title>
    <url>%2F2019%2F12%2F01%2FCNN-Flower-Recognition%2F</url>
    <content type="text"><![CDATA[Tensorflow2.0-Gpu ‰ΩøÁî®CNNÂÆûÁé∞‰∏çÂêåÁßçÁ±ªËä±ÊúµÁöÑËØÜÂà´‰ª£Á†Å123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185import osimport warningswarnings.filterwarnings('always')warnings.filterwarnings('ignore')# data visualisation and manipulationimport numpy as npimport pandas as pdimport matplotlib.pyplot as pltfrom matplotlib import styleimport seaborn as snsprint(os.listdir('/Users/shaoshilin/Desktop/flowers/flowers'))style.use('fivethirtyeight')sns.set(style='whitegrid',color_codes=True)from sklearn.model_selection import train_test_splitfrom sklearn.model_selection import KFoldfrom sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,roc_auc_scorefrom sklearn.model_selection import GridSearchCVfrom sklearn.preprocessing import LabelEncoderfrom keras.preprocessing.image import ImageDataGenerator# dl libraraiesfrom keras import backend as Kfrom keras.models import Sequentialfrom keras.layers import Densefrom keras.optimizers import Adam, SGD, Adagrad, Adadelta, RMSpropfrom keras.utils import to_categoricalfrom keras.layers import Dropout, Flatten, Activationfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalizationimport tensorflow as tfimport random as rnimport cv2import numpy as npfrom tqdm import tqdmimport osfrom random import shufflefrom zipfile import ZipFilefrom PIL import ImageX=[]Z=[]IMG_SIZE=150FLOWER_DAISY_DIR="/Users/shaoshilin/Desktop/flowers/flowers/daisy/"FLOWER_SUNFLOWER_DIR="/Users/shaoshilin/Desktop/flowers/flowers/sunflower/"FLOWER_TULIP_DIR="/Users/shaoshilin/Desktop/flowers/flowers/tulip/"FLOWER_DANDI_DIR="/Users/shaoshilin/Desktop/flowers/flowers/dandelion/"FLOWER_ROSE_DIR="/Users/shaoshilin/Desktop/flowers/flowers/rose/"def assign_label(img,flower_type): return flower_typedef make_train_data(flower_type, DIR): for img in tqdm(os.listdir(DIR)): label = assign_label(img, flower_type) path = os.path.join(DIR, img) #print(path) img = cv2.imread(path, cv2.IMREAD_COLOR) img = cv2.resize(img, (IMG_SIZE, IMG_SIZE)) X.append(np.array(img)) Z.append(str(label))make_train_data('Daisy',FLOWER_DAISY_DIR)print(len(X))make_train_data('Tulip',FLOWER_TULIP_DIR)print(len(X))make_train_data('Dandelion',FLOWER_DANDI_DIR)print(len(X))make_train_data('Rose',FLOWER_ROSE_DIR)print(len(X))make_train_data('Sunflower',FLOWER_SUNFLOWER_DIR)print(len(X))fig,ax=plt.subplots(5,2)fig.set_size_inches(15,15)for i in range(5): for j in range (2): l=rn.randint(0,len(Z)) ax[i,j].imshow(X[l]) ax[i,j].set_title('Flower: '+Z[l]) plt.tight_layout()le=LabelEncoder()Y=le.fit_transform(Z)Y=to_categorical(Y,5)X=np.array(X)X=X/255x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.25,random_state=42)np.random.seed(42)rn.seed(42)tf.random.set_seed(42)model = Sequential()model.add(Conv2D(filters=32, kernel_size=(5, 5), padding='Same', activation='relu', input_shape=(150, 150, 3)))model.add(MaxPooling2D(pool_size=(2, 2)))model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='Same', activation='relu'))model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))model.add(Conv2D(filters=96, kernel_size=(3, 3), padding='Same', activation='relu'))model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))model.add(Conv2D(filters=96, kernel_size=(3, 3), padding='Same', activation='relu'))model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))model.add(Flatten())model.add(Dense(512))model.add(Activation('relu'))model.add(Dense(5, activation="softmax"))batch_size=128epochs=50from keras.callbacks import ReduceLROnPlateaured_lr= ReduceLROnPlateau(monitor='val_acc',patience=3,verbose=1,factor=0.1)datagen = ImageDataGenerator( featurewise_center=False, # set input mean to 0 over the dataset samplewise_center=False, # set each sample mean to 0 featurewise_std_normalization=False, # divide inputs by std of the dataset samplewise_std_normalization=False, # divide each input by its std zca_whitening=False, # apply ZCA whitening rotation_range=10, # randomly rotate images in the range (degrees, 0 to 180) zoom_range = 0.1, # Randomly zoom image width_shift_range=0.2, # randomly shift images horizontally (fraction of total width) height_shift_range=0.2, # randomly shift images vertically (fraction of total height) horizontal_flip=True, # randomly flip images vertical_flip=False) # randomly flip imagesdatagen.fit(x_train)model.compile(optimizer=Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])model.summary()History = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size), epochs = epochs, validation_data = (x_test,y_test), verbose = 1, steps_per_epoch=x_train.shape[0] // batch_size)plt.plot(History.history['loss'])plt.plot(History.history['val_loss'])plt.title('Model Loss')plt.ylabel('Loss')plt.xlabel('Epochs')plt.legend(['train', 'test'])plt.show()plt.plot(History.history['accuracy'])plt.plot(History.history['val_accuracy'])plt.title('Model Accuracy')plt.ylabel('Accuracy')plt.xlabel('Epochs')plt.legend(['train', 'test'])plt.show()# getting predictions on val set.pred=model.predict(x_test)print(pred.shape)pred_digits=np.argmax(pred,axis=1)print(pred_digits.shape)i=0prop_class=[]mis_class=[]for i in range(len(y_test)): if(np.argmax(y_test[i])==pred_digits[i]): prop_class.append(i) if(len(prop_class)==8): breaki=0for i in range(len(y_test)): if(not np.argmax(y_test[i])==pred_digits[i]): mis_class.append(i) if(len(mis_class)==8): breakwarnings.filterwarnings('always')warnings.filterwarnings('ignore')count=0fig,ax=plt.subplots(4,2)fig.set_size_inches(15,15)for i in range (4): for j in range (2): ax[i,j].imshow(x_test[mis_class[count]]) ax[i,j].set_title("Predicted Flower :"+str(le.inverse_transform([pred_digits[mis_class[count]]]))+"\n"+"Actual Flower : "+str(le.inverse_transform([np.argmax(y_test[prop_class[count]])]))) plt.tight_layout() count+=1 ÂÆåÊï¥‰ª£Á†Å‰Ωç‰∫éÊàëÁöÑgithub]]></content>
      <categories>
        <category>‰Ωú‰∏ö</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TextRankÂ§ß‰Ωú‰∏ö]]></title>
    <url>%2F2019%2F11%2F23%2FTextRank%E5%A4%A7%E4%BD%9C%E4%B8%9A%2F</url>
    <content type="text"><![CDATA[‰ª£Á†ÅÂ§çÁé∞ËøáÁ®ãbuild Undirectetweighted Graph123456789101112131415161718192021222324252627282930313233343536373839404142434445from collections import defaultdictfrom jieba.analyse.tfidf import KeywordExtractorimport jieba.possegimport sysfrom operator import itemgetterclass UndirectWeightedGraph: d = 0.85 def __init__(self): self.graph = defaultdict(list) def addEdge(self,start,end,weight): # use a tuple(start,end,weight) instead of a Edge object self.graph[start].append((start,end,weight)) self.graph[end].append((end,start,weight)) def rank(self): ws = defaultdict(float) outSum = defaultdict(float) wsdef = 1.0/(len(self.graph) or 1.0) for n,out in self.graph.items(): ws[n]=wsdef for e in out: outSum[n]=sum((e[2] for e in out),0.0) # this line for build stable iteration sorted_keys=sorted(self.graph.keys()) for x in range(10): for n in sorted_keys: s = 0 for e in self.graph[n]: s += (e[2]*ws[e[1]])/(outSum[e[1]]) ws[n]=(1-self.d)+self.d*s (min_rank,max_rank) = (sys.float_info[0],sys.float_info[3]) # print(min_rank,max_rank) for w in ws.values(): if w&lt;min_rank: min_rank = w if w&gt;max_rank: max_rank = w for n,w in ws.items(): # we can also choose *100 but this way is better ws[n]=(w-min_rank/10.0)/(max_rank-min_rank/10.0) return ws# g = UndirectWeightedGraph()# g.addEdge('a','b',3)# g.addEdge('a','c',2)# g.rank() rank for text12345678910111213141516171819202122232425262728293031323334353637383940414243444546class TextRank(KeywordExtractor): def __init__(self): self.tokenizer = self.postokenizer=jieba.posseg.dt self.stop_words = self.STOP_WORDS.copy() # print(self.stop_words) self.pos_filt = frozenset(('ns','n','vn','v')) self.span = 5 #get ÂêçËØç,Âä®ËØç,ÂêçÂä®ËØç,Âú∞Âêç def pairfilter(self,wp): return (wp.flag in self.pos_filt and len(wp.word.strip())&gt;=2 and wp.word.lower() not in self.stop_words) def textrank(self, sentence, topK=20, withWeight=False, allowPOS=('ns', 'n', 'vn', 'v'), withFlag=False): self.pos_filt = frozenset(allowPOS) g=UndirectWeightedGraph() cm = defaultdict(int) words = tuple(self.tokenizer.cut(sentence)) #print(type(words)) #print(type(words[0])) for i,wp in enumerate(words): if self.pairfilter(wp): for j in range(i+1,i+self.span): if j&gt;=len(words): break if not self.pairfilter(words[j]): continue if allowPOS and withFlag: cm[(wp,words[j])]+=1 else: cm[(wp.word,words[j].word)]+=1 for terms,w in cm.items(): g.addEdge(terms[0],terms[1],w) nodes_rank = g.rank() # print(nodes_rank.items()) if withWeight: tags = sorted(nodes_rank.items(),key=itemgetter(1),reverse=True) else: tags = sorted(nodes_rank,key=nodes_rank.__getitem__,reverse=True) if topK: return tags[:topK] else: return tagsf = open('test.txt',encoding='utf-8')s = f.read()ans = TextRank()print(ans.textrank(s,topK=20,withWeight=True,allowPOS=('ns','v','vn','n'),withFlag=True))]]></content>
      <categories>
        <category>‰Ωú‰∏ö</category>
      </categories>
      <tags>
        <tag>‰Ωú‰∏ö</tag>
        <tag>textrank</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êï∞ÊçÆÂàÜÊûêËÄÉËØï]]></title>
    <url>%2F2019%2F11%2F23%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E8%80%83%E8%AF%95%2F</url>
    <content type="text"><![CDATA[ÈÄâÊã©È¢ò Êï∞ÊçÆÊåñÊéòË°å‰∏∫ÔºöÊï∞ÊçÆÊåñÊéòÊòØÂú®Â§ßÂûãÊï∞ÊçÆÂ≠òÂÇ®Â∫ì‰∏≠ÔºåËá™Âä®Âú∞ÂèëÁé∞ÊúâÁî®‰ø°ÊÅØÁöÑËøáÁ®ã„ÄÇËøòÂèØ‰ª•È¢ÑÊµãÊú™Êù•ËßÇÊµãÁªìÊûú Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÁöÑÊñπÊ≥ïÔºö ËÅöÈõÜ ÊäΩÊ†∑ Áª¥ÂΩíÁ∫¶ ÁâπÂæÅÂ≠êÈõÜÈÄâÊã© ÁâπÂæÅÂàõÂª∫ Á¶ªÊï£ÂåñÂíå‰∫åÂÖÉÂåñ ÂèòÈáèÂèòÊç¢ Áõ∏‰ººÂ∫¶Â∫¶ÈáèÊåáÊ†áÔºö ÂèØËßÜÂåñÊñπÊ≥ïÔºö Â∞ëÈáèÂ±ûÊÄßÁöÑÂèØËßÜÂåñÔºö ËåéÂè∂Âõæ Áõ¥ÊñπÂõæ ‰∫åÁª¥Áõ¥ÊñπÂõæ ÁõíË£ÖÂõæ È•ºÂõæ ÁôæÂàÜ‰ΩçÂõæÂíåÁªèÈ™åÁ¥ØËÆ°ÂàÜÂ∏ÉÂáΩÊï∞ Êï£Â∏ÉÂõæ ÂèØËßÜÂåñÊó∂Èó¥Á©∫Èó¥Êï∞ÊçÆ Á≠âÈ´òÁ∫øÂõæ Êõ≤Èù¢Âõæ Áü¢ÈáèÂú∫Âõæ ‰ΩéÁª¥ÂàáÁâá ÂèØËßÜÂåñÈ´òÁª¥Êï∞ÊçÆ Áü©Èòµ Âπ≥Ë°åÂùêÊ†áÁ≥ª ÊòüÂΩ¢ÂùêÊ†áÁ≥ªÂíåChernoffËÑ∏ ÂÜ≥Á≠ñÊ†ëÁªìÊûÑÔºö ÂÜ≥Á≠ñÊ†ëÊòØ‰∏ÄÁßçÁî±ËäÇÁÇπÂíåÊúâÂêëËæπÁªÑÊàêÁöÑÂ±ÇÊ¨°ÁªìÊûÑÔºåÊ†ë‰∏≠ÂåÖÂê´‰∏âÁßçËäÇÁÇπÔºö 1. Ê†πÁªìÁÇπÔºåÊ≤°ÊúâÂÖ•ËæπÔºåÊúâÈõ∂Êù°ÊàñËÄÖÂ§öÊù°Âá∫Ëæπ 2. ÂÜÖÈÉ®ËäÇÁÇπÔºåÊÅ∞Êúâ‰∏ÄÊù°ÂÖ•ËæπÔºå‰∏§Êù°ÊàñËÄÖÂ§öÊù°Âá∫Ëæπ 3. Âè∂ËäÇÁÇπÊàñÊòØÁªàÁªìÁÇπÔºåÊÅ∞Êúâ‰∏ÄÊù°ÂÖ•ËæπÔºåÊ≤°ÊúâÂá∫Ëæπ ÂàÜÁ±ªÊ®°ÂûãÁöÑËØØÂ∑ÆÔºö ÊúÄ‰Ω≥ÂàÜÁ±ªÁöÑÂ∫¶Èáè ÂàÜÁ±ªËßÑÂàôÁöÑÂ∫¶Èáè ÂÖ≥ËÅîËßÑÂàôÁöÑÂ∫¶Èáè kÂùáÂÄºËÅöÁ±ªÁÆóÊ≥ïÁöÑ‰ºòÁº∫ÁÇπ ÁÆÄÁ≠îÈ¢ò]]></content>
      <categories>
        <category>‰Ωú‰∏ö</category>
      </categories>
      <tags>
        <tag>‰Ωú‰∏ö</tag>
        <tag>Êï∞ÊçÆÊåñÊéò</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Regular Expression]]></title>
    <url>%2F2019%2F11%2F19%2FRegular-Expression%2F</url>
    <content type="text"><![CDATA[Ê≠£ÂàôË°®ËææÂºèÔºåÊü•ÊâæÁ¨¶ÂêàËßÑÂàôÁöÑÂ≠óÁ¨¶‰∏≤ÔºåÊ≠£ÂàôË°®ËææÂºèÂ∞±ÊòØÁî®‰∫éÊèèËø∞Ëøô‰∫õËßÑÂàôÁöÑÂ∑•ÂÖ∑Ë°åÂÆö‰ΩçÁ¨¶1.Áî®Êù•ÊèèËø∞Â≠óÁ¨¶‰∏≤ÁöÑËæπÁïåÔºå‚Äù^‚Äù Ë°®Á§∫Ë°åÁöÑÂºÄÂßãÔºå‚Äù$‚ÄùË°®Á§∫Ë°åÁöÑÁªìÂ∞æ]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>re</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ëâ≤ÂΩ©Â≠¶‰Ωú‰∏ö]]></title>
    <url>%2F2019%2F11%2F11%2F%E8%89%B2%E5%BD%A9%E5%AD%A6%E4%BD%9C%E4%B8%9A%2F</url>
    <content type="text"><![CDATA[‰ª£Á†Å‰Ωç‰∫éÊàëÁöÑgithub Ê¨¢ËøéforkËâ≤ÂΩ©Â≠¶ÂÆûÈ™å‰∏ÄÔºöÈ¢úËâ≤‰∏âÂà∫ÊøÄÂÄºÁöÑËÆ°ÁÆó‰∏âÂà∫ÊøÄÂÄºÁöÑÊ¶ÇÂøµÔºöÊ∑∑Ëâ≤Á≥ªÁªüÊòØÊ†πÊçÆËâ≤Â∫¶Â≠¶ÁöÑÁêÜËÆ∫ÂíåÂÆûÈ™åËØÅÊòé‰ªª‰ΩïËâ≤ÂΩ©ÈÉΩÂèØ‰ª•ÊúâËâ≤ÂÖâÁöÑ‰∏âÂéüËâ≤Ê∑∑ÂêàÂæóÂà∞ËÄåÂª∫Á´ãÁöÑ„ÄÇËâ≤Â∫¶‰∏âÂéüËâ≤ÊòØÁ∫¢„ÄÅÁªø„ÄÅËìù„ÄÇÂà©Áî®Á∫¢„ÄÅÁªø„ÄÅËìù‰∏âËâ≤ÂÖâÂèØ‰ª•Ê∑∑ÂêàÂåπÈÖçÂá∫‰ªª‰ΩïÊÉ≥Ë¶ÅÁöÑÈ¢úËâ≤ÔºåÂØπ‰∫éÁâ©‰ΩìÁöÑË°®Èù¢Ëâ≤ÔºåÈúÄË¶ÅÁî®‰ª™Âô®ÊµãÂÆöÂÖ∂ÊâÄÂèçÂ∞ÑÊàñËÄÖÊäïÂ∞ÑÁöÑ‰∏âÂéüËâ≤ÂÖâÁöÑÊï∞ÈáèÔºåÊ≠§‰∏âÂéüËâ≤Ëâ≤ÂÖâÁöÑ‰ΩúÁî®ÈáèÊàê‰∏∫Ëâ≤ÂΩ©ÁöÑ‰∏âÂà∫ÊøÄÂÄº„ÄÇ CIE 1931 RGB Ë°®Ëâ≤Á≥ªÁªüÔºö Áî±‰∫éÂ§ñÁïåÁöÑÂÖâËæêÂ∞Ñ‰ΩúÁî®‰∫é‰∫∫ÂéåÔºåÂõ†ËÄå‰∫ßÁîüÈ¢úËâ≤ÁöÑÊÑüËßâÔºåËøôËØ¥ÊòéÔºåÁâ©‰ΩìÁöÑÈ¢úËâ≤Êó¢ÂèñÂÜ≥‰∫éÁâ©ÁêÜÂà∫ÊøÄÔºåÂèàÂèñÂÜ≥‰∫é‰∫∫ÁúºÁöÑÁâπÊÄß„ÄÇ‰∏∫‰∫ÜÂÆöÈáèÁöÑË°®Á§∫È¢úËâ≤Ôºå‰∫éÊòØÊúâ‰∫Ü‚ÄúÊ†áÂáÜËâ≤Â∫¶ËßÇÂØüËÄÖ‚ÄùÂèàÁß∞ÂÖ®ÈÉ®ÁöÑÂÖâË∞±‰∏âÂà∫ÊøÄÂÄº Ëâ≤Â∫¶ÂùêÊ†áÁöÑÊ¶ÇÂøµÔºöÂú®Ëâ≤Â∫¶Â≠¶‰ΩìÁ≥ª‰∏≠Ôºå‰∏çÁõ¥Êé•Áî®‰∏âÂà∫ÊøÄÂÄºÊù•Ë°®Á§∫È¢úËâ≤ÔºåËÄåÊòØÁî®‰∏âÂéüËâ≤‰∏™Â≠óÂú®‰∏âÂéüËâ≤ÊÄªÈáèÔºàR+G+BÔºâ‰∏≠ÁöÑÊØî‰æãÊù•Ë°®Á§∫È¢úËâ≤ÔºåÁõ∏ÂØπÊØî‰æãÂè´ÂÅöËâ≤Â∫¶ÂùêÊ†á„ÄÇ CIE 1931 XYZ Á≥ªÁªüÁöÑÂª∫Á´ãÂú®CIE1931RGBËâ≤Â∫¶Á≥ªÁªü‰∏≠ËÆ°ÁÆóÈ¢úËâ≤ÁöÑ‰∏âÂà∫ÊøÄÂÄºÊó∂‰ºöÂá∫Áé∞Ë¥üÂÄºÔºåÁªôÂ∑•‰∏öÂ∏¶Êù•‰∫Ü‰∏ç‰æøÔºåÂõ†Ê≠§Êúâ‰∫ÜCIE 1931 XYZË°®Ëâ≤Á≥ªÁªü XYZÁ≥ªÁªü‰∏éRGBÁ≥ªÁªüÁöÑËâ≤Ê†áËΩ¨Êç¢ÂÖ≥Á≥ª‰∏∫Ôºö CIE 1964 XYZ Ë°•ÂÖÖËâ≤Â∫¶Â≠¶Ë°®Ëâ≤Á≥ªÁªüÔºö‰∫∫ÁúºËßÇÂØüÁâ©‰ΩìÁªÜËäÇÊó∂ÁöÑÂàÜËæ®Âäõ‰∏éËßÇÂØüÊó∂ÁöÑËßÜÂú∫Â§ßÂ∞èÊúâÂÖ≥ÔºåCIE 1931XYZÁ≥ªÁªüÊó∂Âú®2¬∞ËßÜÂú∫‰∏ãÁöÑÂÆûÈ™åÁªìÊûúÔºåÈÄÇÁî®‰∫é&lt;4¬∞ÁöÑËßÜÂú∫ËåÉÂõ¥ÔºåCIE 1964 Ë°•ÂÖÖËâ≤Â∫¶Â≠¶Á≥ªÁªü‰∏∫Âú®10¬∞ËßÜÂú∫‰∏ãÁöÑË°®Ëâ≤Á≥ªÁªü Áâ©‰ΩìÈ¢úËâ≤‰∏âÂà∫ÊøÄÂÄºÁöÑËÆ°ÁÆóËÆ°ÁÆóÊ≠•È™§Ôºö Á°ÆÂÆöÂÖâÊ∫êÂèäÂÖ∂Áõ∏ÂØπÂÖâË∞±ËÉΩÈáèÂàÜÂ∏ÉÔºåÁâ©‰ΩìË°®Èù¢È¢úËâ≤ÂèóÁÖßÂ∞ÑÂÖâÊ∫êËÉΩÈáèÂàÜÂ∏ÉÁöÑÂΩ±ÂìçÔºåÂõ†Ê≠§ÔºåÂú®ÊµãÈáèÁâ©‰ΩìË°®Èù¢Êó∂Ë¶ÅÁ°ÆÂÆöÂÖ∂ÂÖâÊ∫êÔºåÂ¶ÇCIE Ê†áÂáÜÂÖâÊ∫êA„ÄÅB„ÄÅC„ÄÅD50„ÄÅD65Á≠â Á°ÆÂÆöÈ¢úËâ≤ÁöÑÂà∫ÊøÄœÜ(Œª)ÂØπ‰∫éÂÖâÊ∫êËâ≤Ôºö œÜ(Œª) = S(Œª)ÂØπ‰∫éÁâ©‰ΩìËâ≤Ôºö œÜ(Œª) = S(Œª)R(Œª) Áâ©‰Ωì‰∏∫ÂèçÂ∞ÑÁâ©‰ΩìÊó∂R(Œª)‰∏∫Áâ©‰ΩìÂÖâË∞±ÂèçÂ∞ÑÁéáœÅ(Œª)„ÄÇR(Œª)=œÅ(Œª)„ÄÇÂΩìÁâ©‰Ωì‰∏∫ÈÄèÂ∞ÑÁâ©‰ΩìÊó∂R(Œª)‰∏∫ÂÖâË∞±ÈÄèÂ∞ÑÁéá Âç≥R(Œª)=œÑ(Œª) Á°ÆÂÆöÊ†áÂáÜËßÇÂØüËÄÖËßÜÂú∫Á≠âÂ§ßÂ∞è ËÆ°ÁÆóÂÖ¨ÂºèÔºö ËÆ°ÁÆóÂú®ÂÖâÊ∫êD50 2¬∞ËßÜÂú∫‰∏ãÁöÑ‰∏âÂà∫ÊøÄÂÄº Êï∞ÊçÆ‰ª£Á†ÅÊîæÂú®ÊàëÁöÑgithubÈáåÈù¢123456789101112131415161718192021import xlrd # ÂØºÂÖ•Â§ÑÁêÜexcelÁöÑÂ∫ìbook = xlrd.open_workbook('ÂèçÂ∞ÑÁéá.xlsx') #ÊâìÂºÄÂèçÂ∞ÑÁéáË°®Ê†ºbook1 = xlrd.open_workbook("Áõ∏ÂØπÂÖâË∞±ÁéáÂàÜÂ∏É.xlsx") #ÊâìÂºÄÁõ∏ÂØπÂÖâË∞±ÁéáÂàÜÂ∏ÉË°®Ê†ºsheet = book1.sheet_by_index(0) #ËØªÂèñÁõ∏ÂØπÂÖâË∞±ÁéáÂàÜÂ∏ÉË°®Ê†ºÁöÑÁ¨¨‰∏Ä‰∏™sheetsheet1 = book.sheet_by_index(0) # ËØªÂèñÂèçÂ∞ÑÁéáË°®Ê†ºÁöÑÁ¨¨‰∏Ä‰∏™sheetans = 0for i in range(0,len(sheet.col_values(2))): ans=ans+(sheet.col_values(2)[i]*sheet.col_values(4)[i])# Y = K*s(r)*y(r) Ê±ÇÁßØÂàÜÁõ∏Âä†ÁöÑÂΩ¢Âºèk = 100 / ans # Y=100 Ê±ÇKX = 0Y = 0Z = 0for i in range(0,len(sheet1.col_values(0))): X = X+(sheet.col_values(4)[i]*sheet.col_values(1)[i]*sheet1.col_values(1)[i]) Y = Y+(sheet.col_values(4)[i]*sheet.col_values(2)[i]*sheet1.col_values(1)[i]) Z = Z+(sheet.col_values(4)[i]*sheet.col_values(3)[i]*sheet1.col_values(1)[i])X = X * kY = Y * kZ = Z * kprint(X,Y,Z) Ëâ≤ÂΩ©Â≠¶ÂÆûÈ™å‰∫åÔºöÈ™åËØÅ‰∏≠ÂõΩÈ¢úËâ≤‰ΩìÁ≥ªÁöÑÂùáÂåÄÊÄßÁï•Ëâ≤ÂΩ©Â≠¶ÂÆûÈ™å‰∏âCIE 1931 XYZË°®Ëâ≤Á≥ªÁªü‰∏çËÉΩÊª°Ë∂≥‰∫∫‰ª¨ÂØπÈ¢úËâ≤Â∑ÆÂà´ÈáèÁöÑË°®Á§∫È¢úËâ≤ÂÆΩÂÆπÈáèÔºö Ê¶ÇÂøµÔºö‰∫∫ÁúºÊÑüËßâ‰∏çÂá∫Êù•ÁöÑËâ≤ÂΩ©ÁöÑÂ∑ÆÂà´ÈáèÔºàÂèòÂåñËåÉÂõ¥ÔºâÂè´ÂÅöÈ¢úËâ≤ÁöÑÂÆΩÂÆπÈáè„ÄÇ È¢úËâ≤Ëâ≤ÂΩ©ÁöÑÂ∑ÆÂà´ÈáèÂèçÊò†Âú®Ëâ≤Â∫¶Âõæ‰∏äÂ∞±ÊòØÊåáÂú®Ëâ≤Â∫¶Âõæ‰∏ä‰∏§ËÄÖËâ≤Â∫¶ÂùêÊ†á‰πãÈó¥ÁöÑË∑ùÁ¶ª„ÄÇ ‰∏∫‰∫ÜÂÖãÊúçCIE 1931 XYZËâ≤Â∫¶ÂõæÁöÑÁº∫ÁÇπÔºåÈúÄË¶ÅÂàõÂª∫‰∏Ä‰∏™Êñ∞ÁöÑËâ≤Â∫¶ÂõæÔºåÂú®Ëøô‰∏™Ëâ≤Â∫¶Âõæ‰∏äÔºåÊØè‰∏™È¢úËâ≤ÁöÑÂÆΩÂÆπÈáèÊúÄÂ•ΩÈÉΩËøë‰ººÊ§≠ÂúÜÂΩ¢ÔºåËÄå‰∏îÂ§ßÂ∞èÁõ∏ÂêåÔºåÂç≥Ê≠§Á©∫Èó¥‰∏≠ÁöÑË∑ùÁ¶ª‰∏éËßÜËßâ‰∏äÁöÑËâ≤ÂΩ©ÊÑüËßâÂ∑ÆÂà´ÊàêÊ≠£ÊØî„ÄÇÂêåÊó∂ËøòË¶Å‰øùËØÅÊñ∞ÁöÑÈ¢úËâ≤Á©∫Èó¥ÁöÑ‰∏â‰∏™ÂùêÊ†á‰∏ÄÂÆöË¶ÅÁî±ÂéüÊù•ÁöÑXYZ‰∏âÂà∫ÊøÄÂÄºËÆ°ÁÆóÂæóÂá∫ ÂùáÂåÄÈ¢úËâ≤Á©∫Èó¥ÁöÑÂèëÂ±ïCIE1976 L* a* b* ÂùáÂåÄÈ¢úËâ≤Á©∫Èó¥ Êú¨È¢úËâ≤Á©∫Èó¥ÁöÑ‰ºòÁÇπÔºöÂΩìÈ¢úËâ≤ÁöÑËâ≤Â∑ÆÂ§ßÈõ®ËßÜËßâËØÜÂà´ÁöÑÈòàÂÄºËÄåÂèàÂ∞è‰∫éÂ≠üÂ°ûÂ∞îÁ≥ªÁªü‰∏≠Áõ∏ÈÇª‰∏§Á∫ßËâ≤Â∑ÆÊó∂ÔºåÂèØ‰ª•ËæÉÂ•ΩÁöÑÂèçÂ∫îÁâ©‰ΩìËâ≤ÁöÑÂøÉÈáåÊÑüÂèóÊïàÊûú L* a* b* ÂùáÂåÄÈ¢úËâ≤Á©∫Èó¥ÂèäÂÖ∂Ëâ≤Â∑ÆÂÖ¨ÂºèÂèØ‰ª•ÊåâÁÖß‰∏ãÈù¢ÊñπÁ®ãËÆ°ÁÆóÔºö L*=116(Y/Y0)1/3-16a*=500[(X/X0)1/3-(Y/Y0)1/3]b*=200[(Y/Y0)1/3-(Z/Z0)1/3] ÂºèÂ≠ê‰∏≠XYZ‰∏∫È¢úËâ≤Ê†∑ÂìÅÁöÑ‰∏âÂà∫ÊøÄÂÄº ÂºèÂ≠ê‰∏≠X0Y0Z0‰∏∫CIEÊ†áÂáÜÁÖßÊòé‰ΩìÁöÑ‰∏âÂà∫ÊøÄÂÄº L*‰∏∫ÂøÉÁêÜËÆ°ÁÆóÊòéÂ∫¶ÁÆÄÁß∞ÂøÉÁêÜÊòéÂ∫¶ a* b* ‰∏∫ÂøÉÁêÜËÆ°ÈáèËâ≤Â∫¶ Ëâ≤Â∑ÆÂèäÂÖ∂ËÆ°ÁÆóÂÖ¨ÂºèÔºö Áî®Ë∑ùÁ¶ªÂàªÈáè Ëâ≤Â∑ÆÂçï‰ΩçÁöÑÊèêÂá∫Ôºö NBSËâ≤Â∑ÆÂçï‰Ωç CIE1976 L* u* v* ÂùáÂåÄÈ¢úËâ≤Á©∫Èó¥Áï• Ëâ≤Â∑ÆÂÖ¨ÂºèCMCÔºà1:cÔºâ Ëâ≤Â∑ÆÂÖ¨ÂºèCIE94Ëâ≤Â∑ÆÂÖ¨ÂºèCIEDE2000Ëâ≤Â∑ÆÂÖ¨ÂºèÁï•Áï•Áï• ‰ª£Á†ÅÂÆûÁé∞‰ª£Á†ÅÂÆûÁé∞ËøáÁ®ãÔºö‰ª£Á†Å‰∏ÄÔºöÊâãÂä®ÂÆûÁé∞ÔºåÂè™ÂÆûÁé∞‰∫ÜCMC(l:c)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798import pandas as pdimport math#1931D50X0=96.42D50Y0=100D50Z0=82.51#1964D50X0=96.72D50Y0=100D50Z0=81.4#1931D65X0=95.04D65Y0=100D65Z0=108.88#Y0=100x0 = 0.3101y0=0.3162X0 = x0*Y0/y0Z0=(1-x0-y0)*Y0/y0print(Y0,X0,Z0)df = pd.read_excel("lab.xlsx")Y = list()X = list()Z = list()for i in range(0,df.shape[0]): Y.append(df.Y[i]) X.append((df.x[i]*df.Y[i])/df.y[i]) Z.append(((1-df.x[i]-df.y[i])*df.Y[i])/df.y[i])L = list()a = list()b = list()# Â∞ÜYxyËΩ¨Âåñ‰∏∫Labfor i in range(0,len(Y)): L.append(116*pow((Y[i]/Y0),1/3)-16) a.append(500*(pow((X[i]/X0),1/3)-pow((Y[i]/Y0),1/3))) b.append(200*(pow((Y[i]/Y0),1/3)-pow((Z[i]/Z0),1/3)))print('LÂÄº‰∏∫',L)print('aÂÄº‰∏∫',a)print('bÂÄº‰∏∫',b)dotaL = list()dotaa = list()dotab = list()dotaEab = list()for i in range(1,3): dotaL.append(L[i]-L[0]) dotaa.append(a[i]-a[0]) dotab.append(b[i]-b[0]) dotaEab.append(math.sqrt(pow(L[i]-L[0],2)+pow(a[i]-a[0],2)+pow(b[i]-b[0],2)))print("+++++++++++++Ëâ≤Â∑Æ++++++++++++++++++")print("ÊòéÂ∫¶Â∑ÆdotaL:")print(dotaL)print("Ëâ≤Â∫¶Â∑Æ:dotaa ")print(dotaa)print("Ëâ≤Â∫¶Â∑Ædotab")print(dotab)print("ÊÄªËâ≤Â∑Æ:")print(dotaEab)print("+++++++++++++++++++++++++++++++++++")# CMC(1:c) Ëâ≤Â∑ÆÂÖ¨Âºèdef CMC(L1,a1,b1,L2,a2,b2,l,c): C1 = math.sqrt(a1*a1+b1*b1) C2 = math.sqrt(a2*a2+b2*b2) dC=C1-C2 dH = math.sqrt(pow((a1-a2),2)+pow((b1-b2),2)-dC*dC) dL=L1-L2 da=a1-a2 db=b1-b2 if L1&lt;16: SL=0.511 else: SL=(0.040975*L1)/(1+0.01765*L1) SC = (0.0638*C1)/(1+0.0131*C1)+0.638 F = math.sqrt(C1**4/(C1**4+1900)) H = math.atan(b1/a1) if H&gt;0: H1=H else: H1 = H+1 if H1&gt;=(164/360) and H1&lt;=(345/360): T = 0.56+abs(0.2*math.cos(H1+168/360)) else: T = 0.36+abs(0.4*math.cos(H1+35/360)) SH = SC*(F*T+1-F) ans = math.sqrt((dL/(l*SL))**2+(dC/(c*SC))**2+(dH/SH)**2) return ansprint("++++++++++++++++CMC(2:1)Ëâ≤Â∑Æ++++++++++++++++")print(CMC(L[0],a[0],b[0],L[1],a[1],b[1],2,1))print(CMC(L[0],a[0],b[0],L[2],a[2],b[2],2,1))print("++++++++++++++++++++++++++++++++++++++++++++") ÂèØ‰ª•Êé•ÁùÄÊ†πÊçÆÂÖ¨ÂºèÊâãÂä®ÂÆûÁé∞CIE94ÂíåCIEDE2000Ëâ≤Â∑ÆÂÖ¨ÂºèÔºåÂÜôËµ∑Êù•ÁúüÁöÑÁ¥ØÔºåË∞ÉÁî®python ‰∏≠colormathÁöÑÂ∫ìÂÆûÁé∞‰ª£Á†Å‰∫åcolormathËØ¥ÊòéÊñáÊ°£‰ª£Á†Å‰∫åÔºö123456789101112131415161718192021222324252627282930313233# ÂØºÂÖ•colormathÂ∫ìfrom colormath.color_objects import LabColorimport colormathfrom colormath.color_diff import delta_e_cie1994from colormath.color_diff import delta_e_cie2000from colormath.color_diff import delta_e_cmc# ‰ª£Á†Å‰∫åÁúÅÂéªYxyÂà∞LabÁöÑËΩ¨ÂåñL=[87.86741111406972, 87.32443036534754, 85.98144068323823]a=[-15.999098550928403, -15.177720926246751, -12.766918928785065]b=[78.51938967753217, 86.37073015942863, 92.96415914568861]#ËΩ¨Âåñ‰∏∫colormathËÉΩËØªÊáÇÁöÑÊï∞ÊçÆcolor0=LabColor(lab_l=L[0],lab_a=a[0],lab_b=b[0]) color1=LabColor(lab_l=L[1],lab_a=a[1],lab_b=b[1])color2=LabColor(lab_l=L[2],lab_a=a[2],lab_b=b[2])print("++++++++++++++++++CMC(2:1)Ëâ≤Â∑ÆËÆ°ÁÆó++++++++++++++")print(colormath.color_diff.delta_e_cmc(color0, color1, pl=2, pc=1))print(colormath.color_diff.delta_e_cmc(color1, color2, pl=2, pc=1))print(colormath.color_diff.delta_e_cmc(color0, color2, pl=2, pc=1))print("++++++++++++++++++++++++++++++++++++++++++++++++",'\n')print("++++++++++++++CIE94Ëâ≤Â∑ÆËÆ°ÁÆóÂÖ¨Âºè++++++++++++++++++++")print(colormath.color_diff.delta_e_cie1994(color0, color1, K_L=1, K_C=1, K_H=1, K_1=0.045, K_2=0.015))print(colormath.color_diff.delta_e_cie1994(color1, color2, K_L=1, K_C=1, K_H=1, K_1=0.045, K_2=0.015))print(colormath.color_diff.delta_e_cie1994(color0, color2, K_L=1, K_C=1, K_H=1, K_1=0.045, K_2=0.015))print("+++++++++++++++++++++++++++++++++++++++++++++++++",'\n')print("++++++++++++++++CIEDE2000Ëâ≤Â∑ÆÂÖ¨Âºè++++++++++++++++++")print(colormath.color_diff.delta_e_cie2000(color0, color1, Kl=1, Kc=1, Kh=1))print(colormath.color_diff.delta_e_cie2000(color1, color2, Kl=1, Kc=1, Kh=1))print(colormath.color_diff.delta_e_cie2000(color0, color2, Kl=1, Kc=1, Kh=1))print("+++++++++++++++++++++++++++++++++++++++++++++++++")]]></content>
      <categories>
        <category>‰Ωú‰∏ö</category>
      </categories>
      <tags>
        <tag>‰Ωú‰∏ö</tag>
        <tag>Ëâ≤ÂΩ©Â≠¶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êï∞ÊçÆÂàÜÊûêËØæÁ®ãÂÆûÈ™å]]></title>
    <url>%2F2019%2F11%2F10%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%AE%9E%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[ÂìàÂìàÂìàÔºåÂÆûÈ™åÂ§™Êó†ËÅä‰∫ÜÔºåÂÜôÂÜôblogÔºåËÆ∞ÂΩïÊó†ËÅäÁöÑÊï∞ÊçÆÊåñÊéòÂÆûÈ™åËØæÁ®ã„ÄÇÊàëÊòØÂàÜÂâ≤Á∫øÁ∫øÁ∫øÁ∫ø Á¨¨‰∫åÁ´†ÂÆûÈ™åÔºöÂÆûÈ™åÁéØÂ¢ÉÔºöpython3.7ÔºåpycharmÊâÄÊúâ‰ª£Á†ÅÂíåÊï∞ÊçÆÊîæÂú®ÊàëÁöÑgithubÈáåÈù¢Ôºögithub ÂÆûÈ™å‰∏ÄÔºöÁî®ÂÜíÊ≥°ÊéíÂ∫èÂÆûÁé∞ÊéíÂ∫è‰ª£Á†Å123456789def maopao(mylist): for i in range(0,len(mylist)-1): for j in range(0,len(mylist)-i-1): if mylist[j]&gt;mylist[j+1]: mylist[j],mylist[j+1]=mylist[j+1],mylist[j] return mylistSList = [5,6,3,4,8,1,9,0,2]print(maopao(SList)) ÂÆûÈ™å‰∫åÔºöÊääÊó•ÊúüÂíåÊòØÂê¶‰∏∫ËäÇÂÅáÊó•Â≠òÊîæÂà∞Â≠óÂÖ∏ÈáåÈù¢‰ª£Á†Å1234567891011121314151617181920import datetimeimport jsonstarttime=datetime.date(2016,5,1)s = "1605"datedic = &#123;&#125;for i in range(1,32): snum = "%02d"%i today = starttime.replace(day=i) if today.weekday()+1==6 or today.weekday()+1==7: holiday=1 else: holiday=0 datedic[s+snum]=holiday #print(today) #print(today.weekday()+1)#chaxun='160512'#print(datedic[chaxun])with open('holiday.json','w') as f: json.dump(datedic,f) ÂÆûÈ™å‰∏âÔºöËØªÂèñhorseColicÊñá‰ª∂ÔºåÂ∞ÜÊï∞ÊçÆÂíåÊ†áÁ≠æÂàÜÂà´Â≠òÂú®‰∏§‰∏™ÂàóË°®‰∏≠‰ª£Á†Å‰∏Ä12345678910111213dataArr = []labelarr = []with open('horseColic.txt','r') as f: for line in f.readlines(): Arr=[] line=line.strip() s = line.split("\t") Arr = s[:-1] dataArr.append(Arr) labelarr.append(s[-1])print(dataArr[0:3])print(labelarr[0:3]) ‰ª£Á†Å‰∫å1234567891011import pandas as pddataArr = []labelarr = []data=pd.read_csv("horseColic.txt",header=None,sep='\t')for i in range(data.shape[0]): l = list(data.iloc[i,0:21]) dataArr.append(l) labelarr.append(data.loc[i,21])print(dataArr[0:3])print(labelarr[0:3]) Á¨¨‰∏âÁ´†ÂÆûÈ™åÔºöÂÆûÈ™å‰∏ÄÔºöÈÄíÂΩíÊ±ÇÁ¨¨nÈ°πÁöÑÊñêÊ≥¢ÈÇ£Â•ëÊï∞ÂàóÊï∞Âàó‰ª£Á†Å‰∏Ä123456789# f(n) = f(n-1)+f(n-2)# üòÑÊòØÁúüÁöÑÊÖ¢def f(n): if n&lt;=2: return 1 else: return f(n-1)+f(n-2)print(f(10)) ‰ª£Á†Å‰∫åÈùûÈÄíÂΩíÂÆûÁé∞1234567n=100l=[1]*(n+1)l[1]=1l[2]=2for i in range(3,n+1): l[i]=l[i-1]+l[i-2]print(l[n]) Êú™ÂÆåÂæÖÁª≠ÔºÅÔºÅÔºÅÔºÅ]]></content>
      <categories>
        <category>‰Ωú‰∏ö</category>
      </categories>
      <tags>
        <tag>‰Ωú‰∏ö</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Test my Blog]]></title>
    <url>%2F2019%2F05%2F05%2F%E5%BC%A0%E6%98%8E%E8%A5%BF%E5%A4%A7%E4%BD%9C%E4%B8%9A%2F</url>
    <content type="text"><![CDATA[MarkdownÂü∫Êú¨ËØ≠Ê≥ïmarkdownÊòØ‰∏ÄÁßçÂèØ‰ª•ÊòØÊôÆÈÄöÊñáÊú¨ÁºñËæëÂô®ÁºñÂÜôÁöÑÊ†áËÆ∞ËØ≠Ë®Ä„ÄÇ ËøôÊòØ‰∏Ä‰∏™ÊÆµËêΩ ËøôÊòØÊñú‰ΩìËøôÊòØÁ≤ó‰ΩìËøôÊòØÁ≤óÊñú‰Ωì H2 this is first level of quoting this is nested blockquote ËøôÊòØ‰ª£Á†ÅÂå∫ÂüüÔºö123456#include&lt;iostream&gt;using namespace std;int main()&#123;cout&lt;&lt;&quot;shaoshilin&quot;;return 0;&#125;]]></content>
      <categories>
        <category>webÂâçÁ´Ø</category>
      </categories>
      <tags>
        <tag>‰Ωú‰∏ö</tag>
        <tag>ÂÖ∂‰ªñ</tag>
      </tags>
  </entry>
</search>
