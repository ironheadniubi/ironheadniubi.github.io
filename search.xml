<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[CNN Flower Recognition]]></title>
    <url>%2F2019%2F12%2F01%2FCNN-Flower-Recognition%2F</url>
    <content type="text"><![CDATA[Tensorflow2.0-Gpu 使用CNN实现不同种类花朵的识别代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185import osimport warningswarnings.filterwarnings('always')warnings.filterwarnings('ignore')# data visualisation and manipulationimport numpy as npimport pandas as pdimport matplotlib.pyplot as pltfrom matplotlib import styleimport seaborn as snsprint(os.listdir('/Users/shaoshilin/Desktop/flowers/flowers'))style.use('fivethirtyeight')sns.set(style='whitegrid',color_codes=True)from sklearn.model_selection import train_test_splitfrom sklearn.model_selection import KFoldfrom sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,roc_auc_scorefrom sklearn.model_selection import GridSearchCVfrom sklearn.preprocessing import LabelEncoderfrom keras.preprocessing.image import ImageDataGenerator# dl libraraiesfrom keras import backend as Kfrom keras.models import Sequentialfrom keras.layers import Densefrom keras.optimizers import Adam, SGD, Adagrad, Adadelta, RMSpropfrom keras.utils import to_categoricalfrom keras.layers import Dropout, Flatten, Activationfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalizationimport tensorflow as tfimport random as rnimport cv2import numpy as npfrom tqdm import tqdmimport osfrom random import shufflefrom zipfile import ZipFilefrom PIL import ImageX=[]Z=[]IMG_SIZE=150FLOWER_DAISY_DIR="/Users/shaoshilin/Desktop/flowers/flowers/daisy/"FLOWER_SUNFLOWER_DIR="/Users/shaoshilin/Desktop/flowers/flowers/sunflower/"FLOWER_TULIP_DIR="/Users/shaoshilin/Desktop/flowers/flowers/tulip/"FLOWER_DANDI_DIR="/Users/shaoshilin/Desktop/flowers/flowers/dandelion/"FLOWER_ROSE_DIR="/Users/shaoshilin/Desktop/flowers/flowers/rose/"def assign_label(img,flower_type): return flower_typedef make_train_data(flower_type, DIR): for img in tqdm(os.listdir(DIR)): label = assign_label(img, flower_type) path = os.path.join(DIR, img) #print(path) img = cv2.imread(path, cv2.IMREAD_COLOR) img = cv2.resize(img, (IMG_SIZE, IMG_SIZE)) X.append(np.array(img)) Z.append(str(label))make_train_data('Daisy',FLOWER_DAISY_DIR)print(len(X))make_train_data('Tulip',FLOWER_TULIP_DIR)print(len(X))make_train_data('Dandelion',FLOWER_DANDI_DIR)print(len(X))make_train_data('Rose',FLOWER_ROSE_DIR)print(len(X))make_train_data('Sunflower',FLOWER_SUNFLOWER_DIR)print(len(X))fig,ax=plt.subplots(5,2)fig.set_size_inches(15,15)for i in range(5): for j in range (2): l=rn.randint(0,len(Z)) ax[i,j].imshow(X[l]) ax[i,j].set_title('Flower: '+Z[l]) plt.tight_layout()le=LabelEncoder()Y=le.fit_transform(Z)Y=to_categorical(Y,5)X=np.array(X)X=X/255x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.25,random_state=42)np.random.seed(42)rn.seed(42)tf.random.set_seed(42)model = Sequential()model.add(Conv2D(filters=32, kernel_size=(5, 5), padding='Same', activation='relu', input_shape=(150, 150, 3)))model.add(MaxPooling2D(pool_size=(2, 2)))model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='Same', activation='relu'))model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))model.add(Conv2D(filters=96, kernel_size=(3, 3), padding='Same', activation='relu'))model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))model.add(Conv2D(filters=96, kernel_size=(3, 3), padding='Same', activation='relu'))model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))model.add(Flatten())model.add(Dense(512))model.add(Activation('relu'))model.add(Dense(5, activation="softmax"))batch_size=128epochs=50from keras.callbacks import ReduceLROnPlateaured_lr= ReduceLROnPlateau(monitor='val_acc',patience=3,verbose=1,factor=0.1)datagen = ImageDataGenerator( featurewise_center=False, # set input mean to 0 over the dataset samplewise_center=False, # set each sample mean to 0 featurewise_std_normalization=False, # divide inputs by std of the dataset samplewise_std_normalization=False, # divide each input by its std zca_whitening=False, # apply ZCA whitening rotation_range=10, # randomly rotate images in the range (degrees, 0 to 180) zoom_range = 0.1, # Randomly zoom image width_shift_range=0.2, # randomly shift images horizontally (fraction of total width) height_shift_range=0.2, # randomly shift images vertically (fraction of total height) horizontal_flip=True, # randomly flip images vertical_flip=False) # randomly flip imagesdatagen.fit(x_train)model.compile(optimizer=Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])model.summary()History = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size), epochs = epochs, validation_data = (x_test,y_test), verbose = 1, steps_per_epoch=x_train.shape[0] // batch_size)plt.plot(History.history['loss'])plt.plot(History.history['val_loss'])plt.title('Model Loss')plt.ylabel('Loss')plt.xlabel('Epochs')plt.legend(['train', 'test'])plt.show()plt.plot(History.history['accuracy'])plt.plot(History.history['val_accuracy'])plt.title('Model Accuracy')plt.ylabel('Accuracy')plt.xlabel('Epochs')plt.legend(['train', 'test'])plt.show()# getting predictions on val set.pred=model.predict(x_test)print(pred.shape)pred_digits=np.argmax(pred,axis=1)print(pred_digits.shape)i=0prop_class=[]mis_class=[]for i in range(len(y_test)): if(np.argmax(y_test[i])==pred_digits[i]): prop_class.append(i) if(len(prop_class)==8): breaki=0for i in range(len(y_test)): if(not np.argmax(y_test[i])==pred_digits[i]): mis_class.append(i) if(len(mis_class)==8): breakwarnings.filterwarnings('always')warnings.filterwarnings('ignore')count=0fig,ax=plt.subplots(4,2)fig.set_size_inches(15,15)for i in range (4): for j in range (2): ax[i,j].imshow(x_test[mis_class[count]]) ax[i,j].set_title("Predicted Flower :"+str(le.inverse_transform([pred_digits[mis_class[count]]]))+"\n"+"Actual Flower : "+str(le.inverse_transform([np.argmax(y_test[prop_class[count]])]))) plt.tight_layout() count+=1 完整代码位于我的github]]></content>
      <categories>
        <category>作业</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TextRank大作业]]></title>
    <url>%2F2019%2F11%2F23%2FTextRank%E5%A4%A7%E4%BD%9C%E4%B8%9A%2F</url>
    <content type="text"><![CDATA[代码复现过程build Undirectetweighted Graph123456789101112131415161718192021222324252627282930313233343536373839404142434445from collections import defaultdictfrom jieba.analyse.tfidf import KeywordExtractorimport jieba.possegimport sysfrom operator import itemgetterclass UndirectWeightedGraph: d = 0.85 def __init__(self): self.graph = defaultdict(list) def addEdge(self,start,end,weight): # use a tuple(start,end,weight) instead of a Edge object self.graph[start].append((start,end,weight)) self.graph[end].append((end,start,weight)) def rank(self): ws = defaultdict(float) outSum = defaultdict(float) wsdef = 1.0/(len(self.graph) or 1.0) for n,out in self.graph.items(): ws[n]=wsdef for e in out: outSum[n]=sum((e[2] for e in out),0.0) # this line for build stable iteration sorted_keys=sorted(self.graph.keys()) for x in range(10): for n in sorted_keys: s = 0 for e in self.graph[n]: s += (e[2]*ws[e[1]])/(outSum[e[1]]) ws[n]=(1-self.d)+self.d*s (min_rank,max_rank) = (sys.float_info[0],sys.float_info[3]) # print(min_rank,max_rank) for w in ws.values(): if w&lt;min_rank: min_rank = w if w&gt;max_rank: max_rank = w for n,w in ws.items(): # we can also choose *100 but this way is better ws[n]=(w-min_rank/10.0)/(max_rank-min_rank/10.0) return ws# g = UndirectWeightedGraph()# g.addEdge('a','b',3)# g.addEdge('a','c',2)# g.rank() rank for text12345678910111213141516171819202122232425262728293031323334353637383940414243444546class TextRank(KeywordExtractor): def __init__(self): self.tokenizer = self.postokenizer=jieba.posseg.dt self.stop_words = self.STOP_WORDS.copy() # print(self.stop_words) self.pos_filt = frozenset(('ns','n','vn','v')) self.span = 5 #get 名词,动词,名动词,地名 def pairfilter(self,wp): return (wp.flag in self.pos_filt and len(wp.word.strip())&gt;=2 and wp.word.lower() not in self.stop_words) def textrank(self, sentence, topK=20, withWeight=False, allowPOS=('ns', 'n', 'vn', 'v'), withFlag=False): self.pos_filt = frozenset(allowPOS) g=UndirectWeightedGraph() cm = defaultdict(int) words = tuple(self.tokenizer.cut(sentence)) #print(type(words)) #print(type(words[0])) for i,wp in enumerate(words): if self.pairfilter(wp): for j in range(i+1,i+self.span): if j&gt;=len(words): break if not self.pairfilter(words[j]): continue if allowPOS and withFlag: cm[(wp,words[j])]+=1 else: cm[(wp.word,words[j].word)]+=1 for terms,w in cm.items(): g.addEdge(terms[0],terms[1],w) nodes_rank = g.rank() # print(nodes_rank.items()) if withWeight: tags = sorted(nodes_rank.items(),key=itemgetter(1),reverse=True) else: tags = sorted(nodes_rank,key=nodes_rank.__getitem__,reverse=True) if topK: return tags[:topK] else: return tagsf = open('test.txt',encoding='utf-8')s = f.read()ans = TextRank()print(ans.textrank(s,topK=20,withWeight=True,allowPOS=('ns','v','vn','n'),withFlag=True))]]></content>
      <categories>
        <category>作业</category>
      </categories>
      <tags>
        <tag>作业</tag>
        <tag>textrank</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析考试]]></title>
    <url>%2F2019%2F11%2F23%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E8%80%83%E8%AF%95%2F</url>
    <content type="text"><![CDATA[选择题 数据挖掘行为：数据挖掘是在大型数据存储库中，自动地发现有用信息的过程。还可以预测未来观测结果 数据预处理的方法： 聚集 抽样 维归约 特征子集选择 特征创建 离散化和二元化 变量变换 相似度度量指标： 可视化方法： 少量属性的可视化： 茎叶图 直方图 二维直方图 盒装图 饼图 百分位图和经验累计分布函数 散布图 可视化时间空间数据 等高线图 曲面图 矢量场图 低维切片 可视化高维数据 矩阵 平行坐标系 星形坐标系和Chernoff脸 决策树结构： 决策树是一种由节点和有向边组成的层次结构，树中包含三种节点： 1. 根结点，没有入边，有零条或者多条出边 2. 内部节点，恰有一条入边，两条或者多条出边 3. 叶节点或是终结点，恰有一条入边，没有出边 分类模型的误差： 最佳分类的度量 分类规则的度量 关联规则的度量 k均值聚类算法的优缺点 简答题]]></content>
      <categories>
        <category>作业</category>
      </categories>
      <tags>
        <tag>作业</tag>
        <tag>数据挖掘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Regular Expression]]></title>
    <url>%2F2019%2F11%2F19%2FRegular-Expression%2F</url>
    <content type="text"><![CDATA[正则表达式，查找符合规则的字符串，正则表达式就是用于描述这些规则的工具行定位符1.用来描述字符串的边界，”^” 表示行的开始，”$”表示行的结尾]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>re</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[色彩学作业]]></title>
    <url>%2F2019%2F11%2F11%2F%E8%89%B2%E5%BD%A9%E5%AD%A6%E4%BD%9C%E4%B8%9A%2F</url>
    <content type="text"><![CDATA[代码位于我的github 欢迎fork色彩学实验一：颜色三刺激值的计算三刺激值的概念：混色系统是根据色度学的理论和实验证明任何色彩都可以有色光的三原色混合得到而建立的。色度三原色是红、绿、蓝。利用红、绿、蓝三色光可以混合匹配出任何想要的颜色，对于物体的表面色，需要用仪器测定其所反射或者投射的三原色光的数量，此三原色色光的作用量成为色彩的三刺激值。 CIE 1931 RGB 表色系统： 由于外界的光辐射作用于人厌，因而产生颜色的感觉，这说明，物体的颜色既取决于物理刺激，又取决于人眼的特性。为了定量的表示颜色，于是有了“标准色度观察者”又称全部的光谱三刺激值 色度坐标的概念：在色度学体系中，不直接用三刺激值来表示颜色，而是用三原色个字在三原色总量（R+G+B）中的比例来表示颜色，相对比例叫做色度坐标。 CIE 1931 XYZ 系统的建立在CIE1931RGB色度系统中计算颜色的三刺激值时会出现负值，给工业带来了不便，因此有了CIE 1931 XYZ表色系统 XYZ系统与RGB系统的色标转换关系为： CIE 1964 XYZ 补充色度学表色系统：人眼观察物体细节时的分辨力与观察时的视场大小有关，CIE 1931XYZ系统时在2°视场下的实验结果，适用于&lt;4°的视场范围，CIE 1964 补充色度学系统为在10°视场下的表色系统 物体颜色三刺激值的计算计算步骤： 确定光源及其相对光谱能量分布，物体表面颜色受照射光源能量分布的影响，因此，在测量物体表面时要确定其光源，如CIE 标准光源A、B、C、D50、D65等 确定颜色的刺激φ(λ)对于光源色： φ(λ) = S(λ)对于物体色： φ(λ) = S(λ)R(λ) 物体为反射物体时R(λ)为物体光谱反射率ρ(λ)。R(λ)=ρ(λ)。当物体为透射物体时R(λ)为光谱透射率 即R(λ)=τ(λ) 确定标准观察者视场等大小 计算公式： 计算在光源D50 2°视场下的三刺激值 数据代码放在我的github里面123456789101112131415161718192021import xlrd # 导入处理excel的库book = xlrd.open_workbook('反射率.xlsx') #打开反射率表格book1 = xlrd.open_workbook("相对光谱率分布.xlsx") #打开相对光谱率分布表格sheet = book1.sheet_by_index(0) #读取相对光谱率分布表格的第一个sheetsheet1 = book.sheet_by_index(0) # 读取反射率表格的第一个sheetans = 0for i in range(0,len(sheet.col_values(2))): ans=ans+(sheet.col_values(2)[i]*sheet.col_values(4)[i])# Y = K*s(r)*y(r) 求积分相加的形式k = 100 / ans # Y=100 求KX = 0Y = 0Z = 0for i in range(0,len(sheet1.col_values(0))): X = X+(sheet.col_values(4)[i]*sheet.col_values(1)[i]*sheet1.col_values(1)[i]) Y = Y+(sheet.col_values(4)[i]*sheet.col_values(2)[i]*sheet1.col_values(1)[i]) Z = Z+(sheet.col_values(4)[i]*sheet.col_values(3)[i]*sheet1.col_values(1)[i])X = X * kY = Y * kZ = Z * kprint(X,Y,Z) 色彩学实验二：验证中国颜色体系的均匀性略色彩学实验三CIE 1931 XYZ表色系统不能满足人们对颜色差别量的表示颜色宽容量： 概念：人眼感觉不出来的色彩的差别量（变化范围）叫做颜色的宽容量。 颜色色彩的差别量反映在色度图上就是指在色度图上两者色度坐标之间的距离。 为了克服CIE 1931 XYZ色度图的缺点，需要创建一个新的色度图，在这个色度图上，每个颜色的宽容量最好都近似椭圆形，而且大小相同，即此空间中的距离与视觉上的色彩感觉差别成正比。同时还要保证新的颜色空间的三个坐标一定要由原来的XYZ三刺激值计算得出 均匀颜色空间的发展CIE1976 L* a* b* 均匀颜色空间 本颜色空间的优点：当颜色的色差大雨视觉识别的阈值而又小于孟塞尔系统中相邻两级色差时，可以较好的反应物体色的心里感受效果 L* a* b* 均匀颜色空间及其色差公式可以按照下面方程计算： L*=116(Y/Y0)1/3-16a*=500[(X/X0)1/3-(Y/Y0)1/3]b*=200[(Y/Y0)1/3-(Z/Z0)1/3] 式子中XYZ为颜色样品的三刺激值 式子中X0Y0Z0为CIE标准照明体的三刺激值 L*为心理计算明度简称心理明度 a* b* 为心理计量色度 色差及其计算公式： 用距离刻量 色差单位的提出： NBS色差单位 CIE1976 L* u* v* 均匀颜色空间略 色差公式CMC（1:c） 色差公式CIE94色差公式CIEDE2000色差公式略略略 代码实现代码实现过程：代码一：手动实现，只实现了CMC(l:c)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798import pandas as pdimport math#1931D50X0=96.42D50Y0=100D50Z0=82.51#1964D50X0=96.72D50Y0=100D50Z0=81.4#1931D65X0=95.04D65Y0=100D65Z0=108.88#Y0=100x0 = 0.3101y0=0.3162X0 = x0*Y0/y0Z0=(1-x0-y0)*Y0/y0print(Y0,X0,Z0)df = pd.read_excel("lab.xlsx")Y = list()X = list()Z = list()for i in range(0,df.shape[0]): Y.append(df.Y[i]) X.append((df.x[i]*df.Y[i])/df.y[i]) Z.append(((1-df.x[i]-df.y[i])*df.Y[i])/df.y[i])L = list()a = list()b = list()# 将Yxy转化为Labfor i in range(0,len(Y)): L.append(116*pow((Y[i]/Y0),1/3)-16) a.append(500*(pow((X[i]/X0),1/3)-pow((Y[i]/Y0),1/3))) b.append(200*(pow((Y[i]/Y0),1/3)-pow((Z[i]/Z0),1/3)))print('L值为',L)print('a值为',a)print('b值为',b)dotaL = list()dotaa = list()dotab = list()dotaEab = list()for i in range(1,3): dotaL.append(L[i]-L[0]) dotaa.append(a[i]-a[0]) dotab.append(b[i]-b[0]) dotaEab.append(math.sqrt(pow(L[i]-L[0],2)+pow(a[i]-a[0],2)+pow(b[i]-b[0],2)))print("+++++++++++++色差++++++++++++++++++")print("明度差dotaL:")print(dotaL)print("色度差:dotaa ")print(dotaa)print("色度差dotab")print(dotab)print("总色差:")print(dotaEab)print("+++++++++++++++++++++++++++++++++++")# CMC(1:c) 色差公式def CMC(L1,a1,b1,L2,a2,b2,l,c): C1 = math.sqrt(a1*a1+b1*b1) C2 = math.sqrt(a2*a2+b2*b2) dC=C1-C2 dH = math.sqrt(pow((a1-a2),2)+pow((b1-b2),2)-dC*dC) dL=L1-L2 da=a1-a2 db=b1-b2 if L1&lt;16: SL=0.511 else: SL=(0.040975*L1)/(1+0.01765*L1) SC = (0.0638*C1)/(1+0.0131*C1)+0.638 F = math.sqrt(C1**4/(C1**4+1900)) H = math.atan(b1/a1) if H&gt;0: H1=H else: H1 = H+1 if H1&gt;=(164/360) and H1&lt;=(345/360): T = 0.56+abs(0.2*math.cos(H1+168/360)) else: T = 0.36+abs(0.4*math.cos(H1+35/360)) SH = SC*(F*T+1-F) ans = math.sqrt((dL/(l*SL))**2+(dC/(c*SC))**2+(dH/SH)**2) return ansprint("++++++++++++++++CMC(2:1)色差++++++++++++++++")print(CMC(L[0],a[0],b[0],L[1],a[1],b[1],2,1))print(CMC(L[0],a[0],b[0],L[2],a[2],b[2],2,1))print("++++++++++++++++++++++++++++++++++++++++++++") 可以接着根据公式手动实现CIE94和CIEDE2000色差公式，写起来真的累，调用python 中colormath的库实现代码二colormath说明文档代码二：123456789101112131415161718192021222324252627282930313233# 导入colormath库from colormath.color_objects import LabColorimport colormathfrom colormath.color_diff import delta_e_cie1994from colormath.color_diff import delta_e_cie2000from colormath.color_diff import delta_e_cmc# 代码二省去Yxy到Lab的转化L=[87.86741111406972, 87.32443036534754, 85.98144068323823]a=[-15.999098550928403, -15.177720926246751, -12.766918928785065]b=[78.51938967753217, 86.37073015942863, 92.96415914568861]#转化为colormath能读懂的数据color0=LabColor(lab_l=L[0],lab_a=a[0],lab_b=b[0]) color1=LabColor(lab_l=L[1],lab_a=a[1],lab_b=b[1])color2=LabColor(lab_l=L[2],lab_a=a[2],lab_b=b[2])print("++++++++++++++++++CMC(2:1)色差计算++++++++++++++")print(colormath.color_diff.delta_e_cmc(color0, color1, pl=2, pc=1))print(colormath.color_diff.delta_e_cmc(color1, color2, pl=2, pc=1))print(colormath.color_diff.delta_e_cmc(color0, color2, pl=2, pc=1))print("++++++++++++++++++++++++++++++++++++++++++++++++",'\n')print("++++++++++++++CIE94色差计算公式++++++++++++++++++++")print(colormath.color_diff.delta_e_cie1994(color0, color1, K_L=1, K_C=1, K_H=1, K_1=0.045, K_2=0.015))print(colormath.color_diff.delta_e_cie1994(color1, color2, K_L=1, K_C=1, K_H=1, K_1=0.045, K_2=0.015))print(colormath.color_diff.delta_e_cie1994(color0, color2, K_L=1, K_C=1, K_H=1, K_1=0.045, K_2=0.015))print("+++++++++++++++++++++++++++++++++++++++++++++++++",'\n')print("++++++++++++++++CIEDE2000色差公式++++++++++++++++++")print(colormath.color_diff.delta_e_cie2000(color0, color1, Kl=1, Kc=1, Kh=1))print(colormath.color_diff.delta_e_cie2000(color1, color2, Kl=1, Kc=1, Kh=1))print(colormath.color_diff.delta_e_cie2000(color0, color2, Kl=1, Kc=1, Kh=1))print("+++++++++++++++++++++++++++++++++++++++++++++++++")]]></content>
      <categories>
        <category>作业</category>
      </categories>
      <tags>
        <tag>作业</tag>
        <tag>色彩学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析课程实验]]></title>
    <url>%2F2019%2F11%2F10%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E8%AF%BE%E7%A8%8B%E5%AE%9E%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[哈哈哈，实验太无聊了，写写blog，记录无聊的数据挖掘实验课程。我是分割线线线线 第二章实验：实验环境：python3.7，pycharm所有代码和数据放在我的github里面：github 实验一：用冒泡排序实现排序代码123456789def maopao(mylist): for i in range(0,len(mylist)-1): for j in range(0,len(mylist)-i-1): if mylist[j]&gt;mylist[j+1]: mylist[j],mylist[j+1]=mylist[j+1],mylist[j] return mylistSList = [5,6,3,4,8,1,9,0,2]print(maopao(SList)) 实验二：把日期和是否为节假日存放到字典里面代码1234567891011121314151617181920import datetimeimport jsonstarttime=datetime.date(2016,5,1)s = "1605"datedic = &#123;&#125;for i in range(1,32): snum = "%02d"%i today = starttime.replace(day=i) if today.weekday()+1==6 or today.weekday()+1==7: holiday=1 else: holiday=0 datedic[s+snum]=holiday #print(today) #print(today.weekday()+1)#chaxun='160512'#print(datedic[chaxun])with open('holiday.json','w') as f: json.dump(datedic,f) 实验三：读取horseColic文件，将数据和标签分别存在两个列表中代码一12345678910111213dataArr = []labelarr = []with open('horseColic.txt','r') as f: for line in f.readlines(): Arr=[] line=line.strip() s = line.split("\t") Arr = s[:-1] dataArr.append(Arr) labelarr.append(s[-1])print(dataArr[0:3])print(labelarr[0:3]) 代码二1234567891011import pandas as pddataArr = []labelarr = []data=pd.read_csv("horseColic.txt",header=None,sep='\t')for i in range(data.shape[0]): l = list(data.iloc[i,0:21]) dataArr.append(l) labelarr.append(data.loc[i,21])print(dataArr[0:3])print(labelarr[0:3]) 第三章实验：实验一：递归求第n项的斐波那契数列数列代码一123456789# f(n) = f(n-1)+f(n-2)# 😄是真的慢def f(n): if n&lt;=2: return 1 else: return f(n-1)+f(n-2)print(f(10)) 代码二非递归实现1234567n=100l=[1]*(n+1)l[1]=1l[2]=2for i in range(3,n+1): l[i]=l[i-1]+l[i-2]print(l[n]) 未完待续！！！！]]></content>
      <categories>
        <category>作业</category>
      </categories>
      <tags>
        <tag>作业</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Test my Blog]]></title>
    <url>%2F2019%2F05%2F05%2F%E5%BC%A0%E6%98%8E%E8%A5%BF%E5%A4%A7%E4%BD%9C%E4%B8%9A%2F</url>
    <content type="text"><![CDATA[Markdown基本语法markdown是一种可以是普通文本编辑器编写的标记语言。 这是一个段落 这是斜体这是粗体这是粗斜体 H2 this is first level of quoting this is nested blockquote 这是代码区域：123456#include&lt;iostream&gt;using namespace std;int main()&#123;cout&lt;&lt;&quot;shaoshilin&quot;;return 0;&#125;]]></content>
      <categories>
        <category>web前端</category>
      </categories>
      <tags>
        <tag>作业</tag>
        <tag>其他</tag>
      </tags>
  </entry>
</search>
